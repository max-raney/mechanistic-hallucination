[
  {
    "model_id": "google/gemma-2b",
    "load_time_sec": 0.0,
    "inference_time_sec": 0.0,
    "peak_memory_gb": 0.0,
    "tokens_per_sec": 0.0,
    "output_text": "dummy output"
  },
  {
    "model_id": "meta-llama/Meta-Llama-3-8B",
    "load_time_sec": 0.0,
    "inference_time_sec": 0.0,
    "peak_memory_gb": 0.0,
    "tokens_per_sec": 0.0,
    "output_text": "dummy output"
  }
]