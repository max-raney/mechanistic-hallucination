# Mechanistic-Hallucination Project

A replication and extension of CTGT's feature-level interventions for censorship, hallucination, and deception in open-source LLMs.  

---

## Contributors

- Max Raney  
- Ruitian Yang  
- Keshav Ratra  
- Sheng Qian  

---

## Quickstart

1. **Clone & enter**  
   ```bash
   git clone git@github.com:max-raney/mechanistic-hallucination.git
   cd mechanistic-hallucination
   ```

2. **Create & activate virtualenv**  
   ```bash
   python3 -m venv .venv
   source .venv/bin/activate      # Linux / macOS
   .venv\Scripts\activate         # Windows PowerShell
   ```

3. **Install dependencies**  
   ```bash
   pip install -r requirements.txt
   ```

4. **Install CUDA-enabled PyTorch**  
   - **pip** (CUDA 11.8 example)  
     ```bash
     pip uninstall -y torch torchvision torchaudio
     pip install torch torchvision torchaudio \
       --index-url https://download.pytorch.org/whl/cu118
     ```  
   - **conda** (CUDA 11.8 example)  
     ```bash
     conda install pytorch torchvision torchaudio pytorch-cuda=11.8 \
       -c pytorch -c nvidia
     ```

5. **Install in editable mode**  
   ```bash
   pip install -e .
   ```

---

## Model Access

1. Go to https://huggingface.co â†’ **Settings â†’ Access Tokens** â†’ **New token**  
2. Name it, select **read** scope, **Generate**, copy the `hf_â€¦` string  
3. In project root:  
   ```bash
   cp .env.example .env
   ```  
   Edit `.env` to include:  
   ```
   HF_TOKEN=hf_<your-token-here>
   ```

---

## Direction Vector Pipeline

### 1. Train Direction Vectors

Train direction vectors for different concepts (hallucination, refusal, deception) using categorized prompts:

```bash
python -m mechanistic_interventions.scripts.train_direction_vectors \
    --model "google/gemma-2b" \
    --prompts data/prompts.yaml \
    --save_dir direction_vectors/gemma \
    --layer -1 \
    --device cuda
```

- `--model`: HuggingFace model ID or local path
- `--prompts`: Path to YAML file containing categorized prompts
- `--save_dir`: Directory to save trained vectors
- `--layer`: Layer index to extract activations from (-1 for last layer)
- `--device`: Device to use (cuda/cpu)

### 2. Test Direction Vectors

Test the trained vectors by comparing model responses with and without interventions:

```bash
python -m mechanistic_interventions.scripts.test_direction_vectors \
    --model "google/gemma-2b" \
    --prompts data/clean_prompt.txt \
    --vectors_dir direction_vectors/gemma \
    --layer -1 \
    --alpha 10.0 \
    --device cuda \
    --output test_results.json
```

- `--model`: HuggingFace model ID or local path
- `--prompts`: Path to test prompts file (JSON or TXT)
- `--vectors_dir`: Directory containing trained direction vectors
- `--layer`: Layer index to apply interventions (-1 for last layer)
- `--alpha`: Scale factor for interventions
- `--device`: Device to use (cuda/cpu)
- `--output`: Path to save test results

The test results will show:
- Original responses (no intervention)
- Responses with each concept suppressed
- Responses with each concept enhanced

---

## Benchmark Usage

```bash
python -m mechanistic_interventions.evaluation.benchmark \
  [--models MODEL_ID [MODEL_ID ...]] \
  [--prompt "Your prompt"] \
  [--output PATH/TO/results.json]
```

- `--models`: list of HF model IDs (default: `google/gemma-2b meta-llama/Meta-Llama-3-8B`)  
- `--prompt`: text prompt (default: `"Hello, my name is"`)  
- `--output`: output JSON file path (default: `benchmark_results.json`)  

### Quick-exit (CI/tests)

```bash
export MECH_QUICK=1      # Linux/macOS/Git Bash
$Env:MECH_QUICK = '1'    # Windows PowerShell
set MECH_QUICK=1         # Windows CMD

python -m mechanistic_interventions.evaluation.benchmark
# prints: []
```

---

## ðŸ§ª Testing

```bash
pytest -q
```

---

## Project Structure

- `src/mechanistic_interventions/`
  - `direction_vectors/`: Direction vector training and testing
  - `data/`: Prompt datasets and loaders
  - `evaluation/`: Benchmarking and evaluation tools
  - `scripts/`: Command-line tools
  - `sandboxs/`: Model-specific implementations

## Note on Generated Files

The following files and directories are excluded from version control:
- `direction_vectors/`: Trained direction vectors
- `*.pt`: PyTorch model files
- `*.npy`: NumPy array files
- `test_results.json`: Test results
- `benchmark_results.json`: Benchmark results

These files should be generated by running the appropriate scripts.